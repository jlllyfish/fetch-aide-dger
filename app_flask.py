"""
Interface Flask pour la g√©n√©ration d'URLs pr√©-remplies D√©marches Simplifi√©es
√† partir des donn√©es Grist avec design conforme au DSFR.
"""

from flask import Flask, render_template, request, jsonify
import os
import json
import requests
import pandas as pd
import logging
from dotenv import load_dotenv

# Charger les variables d'environnement
load_dotenv()

# Configuration depuis les variables d'environnement
GRIST_API_KEY = os.getenv("GRIST_API_KEY")
GRIST_DOC_ID = os.getenv("GRIST_DOC_ID") 
GRIST_BASE_URL = os.getenv("GRIST_BASE_URL", "https://grist.numerique.gouv.fr/api")
GRIST_TABLE_ID = os.getenv("GRIST_TABLE_ID")
API_TOKEN = os.getenv("API_TOKEN_AIDE")
DEMARCHE_ID = os.getenv("DEMARCHE_ID")

# V√©rification du chargement du .env
print("=== V√âRIFICATION DU FICHIER .ENV ===")
print(f"Fichier .env trouv√©: {os.path.exists('.env')}")
print(f"GRIST_API_KEY charg√©: {'Oui' if GRIST_API_KEY else 'Non'}")
print(f"GRIST_DOC_ID charg√©: {'Oui' if GRIST_DOC_ID else 'Non'}")
print(f"API_TOKEN charg√©: {'Oui' if API_TOKEN else 'Non'}")
print(f"R√©pertoire de travail: {os.getcwd()}")
print("=====================================\n")

app = Flask(__name__)

# Configuration du logging pour supprimer seulement les messages socket.io
class NoSocketIOFilter(logging.Filter):
    def filter(self, record):
        # Filtrer seulement les requ√™tes socket.io, garder les autres messages
        message = record.getMessage()
        return 'socket.io' not in message and 'Socket.IO' not in message

# Appliquer le filtre seulement aux messages de requ√™tes, pas aux messages de d√©marrage
werkzeug_logger = logging.getLogger('werkzeug')
werkzeug_logger.addFilter(NoSocketIOFilter())

# Charger le fichier de configuration de mapping
def load_field_mapping():
    """Charge le mapping des champs depuis le fichier JSON"""
    try:
        # Priorit√© √† la variable d'environnement
        config_file = os.getenv("CONFIG_FILE_PATH")
        
        if not config_file:
            print("‚ùå Variable CONFIG_FILE_PATH non d√©finie dans le .env")
            return {}, None
        
        print(f"üìÅ Tentative de chargement du fichier: {os.path.basename(config_file)}")
        print(f"üìç Chemin complet: {config_file}")
        
        if not os.path.exists(config_file):
            print(f"‚ùå Fichier non trouv√©: {config_file}")
            
            # Debug: lister tous les fichiers JSON du r√©pertoire
            directory = os.path.dirname(config_file)
            if os.path.exists(directory):
                print(f"üìÇ Fichiers JSON disponibles dans le r√©pertoire:")
                for file in os.listdir(directory):
                    if file.endswith('.json'):
                        print(f"   - {file}")
                        
            return {}, config_file
            
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        field_mappings = config.get("field_mappings", {})
        
        # Inverser le mapping : colonne_grist -> id_ds
        # Dans le JSON: "Q2hhbXAtNjIyMzQw": {"columnId": "titre_du_projet"}
        # On veut: "titre_du_projet" -> "Q2hhbXAtNjIyMzQw"
        inverted_mapping = {}
        for ds_field_id, mapping_info in field_mappings.items():
            grist_column = mapping_info.get("columnId")
            if grist_column:
                inverted_mapping[grist_column] = ds_field_id
        
        print(f"‚úÖ Fichier charg√© avec succ√®s. Mappings trouv√©s: {len(inverted_mapping)}")
        print(f"üìã Mappings configur√©s:")
        for grist_col, ds_id in inverted_mapping.items():
            print(f"   {grist_col} -> {ds_id}")
        
        return inverted_mapping, config_file
        
    except Exception as e:
        print(f"‚ùå Erreur lors du chargement du mapping: {e}")
        return {}, None

# Charger le mapping au d√©marrage
FIELD_MAPPING, CONFIG_FILE_LOADED = load_field_mapping()

class GristClient:
    def __init__(self):
        self.base_url = GRIST_BASE_URL.rstrip('/')
        self.api_key = GRIST_API_KEY
        self.doc_id = GRIST_DOC_ID
        self.headers = {"Authorization": f"Bearer {self.api_key}"}

    def get_table_data(self, table_id):
        """R√©cup√®re les donn√©es d'une table Grist"""
        url = f"{self.base_url}/docs/{self.doc_id}/tables/{table_id}/records"
        
        try:
            response = requests.get(url, headers=self.headers)
            response.raise_for_status()
            
            data = response.json()
            if 'records' not in data:
                return pd.DataFrame()
            
            # Extraire les donn√©es
            rows = []
            for record in data['records']:
                if 'fields' in record:
                    row_data = record['fields'].copy()
                    row_data['id'] = record.get('id')
                    rows.append(row_data)
            
            return pd.DataFrame(rows)
        
        except Exception as e:
            print(f"Erreur lors de la r√©cup√©ration des donn√©es: {e}")
            return pd.DataFrame()

def find_display_columns(df):
    """
    Trouve automatiquement les colonnes √† afficher dans le tableau avec noms personnalis√©s
    """
    email_column = None
    dossier_column = None
    nom_column = None
    pays_column = None
    
    print(f"üîç Analyse des colonnes disponibles: {list(df.columns)}")
    
    for col in df.columns:
        col_lower = col.lower()
        
        # Recherche de colonnes email
        email_patterns = ['email', 'mail', 'e-mail', 'e_mail', 'courriel']
        if any(pattern in col_lower for pattern in email_patterns):
            email_column = col
            print(f"‚úÖ Colonne email trouv√©e: {col}")
        
        # Recherche de colonnes dossier - VERSION AM√âLIOR√âE
        elif any(pattern in col_lower for pattern in [
            'numero_dossier', 'num√©ro_dossier', 
            'numero dossier', 'num√©ro dossier',
            'dossier_number', 'dossier number',
            'dossier_num', 'dossier num',
            'num_dossier', 'num dossier',
            'id_dossier', 'id dossier'
        ]):
            dossier_column = col
            print(f"‚úÖ Colonne dossier trouv√©e: {col}")
        
        # Recherche de la colonne Nom (Nom_maj_) - RECHERCHE PR√âCISE
        elif col.lower() in ['nom_maj_', 'nom_maj'] or col == 'Nom_maj_':
            nom_column = col
            print(f"‚úÖ Colonne nom trouv√©e: {col}")
        
        # Recherche de la colonne Pays
        elif col_lower in ['pays', 'country', 'pays_', 'country_']:
            pays_column = col
            print(f"‚úÖ Colonne pays trouv√©e: {col}")
    
    # Valeurs par d√©faut si rien trouv√©
    if not email_column:
        email_column = 'email'
        print(f"‚ö†Ô∏è Aucune colonne email trouv√©e, utilisation par d√©faut: {email_column}")
    
    if not dossier_column:
        dossier_column = 'dossier_number'
        print(f"‚ö†Ô∏è Aucune colonne dossier trouv√©e, utilisation par d√©faut: {dossier_column}")
    
    if not nom_column:
        nom_column = 'Nom_maj_'
        print(f"‚ö†Ô∏è Aucune colonne nom trouv√©e, utilisation par d√©faut: {nom_column}")
    
    if not pays_column:
        pays_column = 'Pays'
        print(f"‚ö†Ô∏è Aucune colonne pays trouv√©e, utilisation par d√©faut: {pays_column}")
    
    # Construire la configuration des colonnes avec mapping nom de colonne -> nom d'affichage
    columns_config = [
        {'column': email_column, 'display': 'Email'},
        {'column': dossier_column, 'display': 'Num√©ro de dossier'},
        {'column': nom_column, 'display': 'Nom'},
        {'column': pays_column, 'display': 'Pays'}
    ]
    
    print(f"üìä Configuration finale des colonnes:")
    for config in columns_config:
        print(f"   {config['column']} -> {config['display']}")
    
    return columns_config

def clean_prefill_data_for_ds(prefill_data):
    """
    Nettoie et formate les donn√©es de pr√©-remplissage pour l'API DS
    Version corrig√©e qui re-parse les champs multiples re√ßus comme cha√Ænes
    """
    cleaned_data = {}
   
    for field_key, value in prefill_data.items():
        if value is None or value == "":
            continue
       
        # ‚úÖ CORRECTION MAJEURE : Pr√©server les tableaux pour les champs multiples
        if isinstance(value, list):
            # C'est d√©j√† un tableau (champ multiple trait√© c√¥t√© client)
            if len(value) > 0:
                # Nettoyer chaque valeur du tableau SANS le transformer en cha√Æne
                cleaned_values = []
                for v in value:
                    if v is not None and str(v).strip():
                        # Nettoyer les retours √† la ligne dans chaque valeur
                        clean_val = str(v).strip()
                        clean_val = clean_val.replace('\r\n', ' ').replace('\r', ' ').replace('\n', ' ')
                        clean_val = ' '.join(clean_val.split())  # Remplacer multiples espaces
                        cleaned_values.append(clean_val)
               
                if cleaned_values:
                    # ‚úÖ GARDER LE FORMAT TABLEAU pour l'API DS
                    cleaned_data[field_key] = cleaned_values
                    print(f"üîó Champ multiple {field_key}: {len(cleaned_values)} valeur(s) ‚Üí {cleaned_values}")
       
        else:
            # ‚úÖ NOUVEAU : D√©tecter les champs multiples re√ßus comme cha√Ænes et les re-parser
            cleaned_value = str(value).strip()
           
            if cleaned_value:
                # Nettoyer les retours √† la ligne
                cleaned_value = cleaned_value.replace('\r\n', ' ').replace('\r', ' ').replace('\n', ' ')
                cleaned_value = ' '.join(cleaned_value.split())  # Remplacer multiples espaces
               
                # ‚úÖ D√âTECTION : Si la cha√Æne contient des virgules, c'est probablement un champ multiple mal s√©rialis√©
                if ',' in cleaned_value and len(cleaned_value.split(',')) > 1:
                    # Re-parser comme champ multiple
                    parsed_values = [v.strip() for v in cleaned_value.split(',') if v.strip()]
                    if len(parsed_values) > 1:
                        cleaned_data[field_key] = parsed_values
                        print(f"üîó Champ multiple re-pars√© {field_key}: cha√Æne ‚Üí {len(parsed_values)} valeur(s) ‚Üí {parsed_values}")
                    else:
                        cleaned_data[field_key] = cleaned_value
                        print(f"üìù Champ simple {field_key}: {cleaned_value[:50]}...")
                else:
                    cleaned_data[field_key] = cleaned_value
                    print(f"üìù Champ simple {field_key}: {cleaned_value[:50]}...")
   
    # ‚úÖ NOUVEAU : Log de r√©sum√©
    total_fields = len(cleaned_data)
    multiple_fields = sum(1 for value in cleaned_data.values() if isinstance(value, list))
    simple_fields = total_fields - multiple_fields
   
    print(f"üìä DONN√âES NETTOY√âES POUR DS: {total_fields} champ(s) total - {simple_fields} simples, {multiple_fields} multiples")
   
    return cleaned_data

def generate_prefilled_url(row_data, field_mapping):
    """G√©n√®re une URL pr√©-remplie pour D√©marches Simplifi√©es"""
    
    if not API_TOKEN:
        return "Erreur: Token API manquant"
    
    if not field_mapping:
        return "Erreur: Mapping des champs non disponible"
    
    api_url = f'https://www.demarches-simplifiees.fr/api/public/v1/demarches/{DEMARCHE_ID}/dossiers'
    headers = {
        "Content-Type": "application/json", 
        "Authorization": f"Bearer {API_TOKEN}"
    }
    
    # Debug: afficher les donn√©es d'entr√©e
    print(f"üîç Donn√©es de la ligne Grist:")
    for key, value in row_data.items():
        print(f"   {key}: {value}")
    
    # Mapper les donn√©es aux champs DS
    mapped_data = {}
    mapped_count = 0
    
    for field_name, field_value in row_data.items():
        if field_name in field_mapping:
            ds_field_id = field_mapping[field_name]
            mapped_data[f"champ_{ds_field_id}"] = field_value
            mapped_count += 1
            print(f"‚úÖ Mapping: {field_name} -> champ_{ds_field_id} = {field_value}")
        else:
            print(f"‚ö†Ô∏è Champ non mapp√©: {field_name}")
    
    print(f"üìä Total champs mapp√©s: {mapped_count}")
    print(f"üì§ Donn√©es brutes envoy√©es √† DS: {mapped_data}")
    
    # ‚úÖ NOUVEAU : Nettoyer les donn√©es pour g√©rer les champs multiples
    cleaned_data = clean_prefill_data_for_ds(mapped_data)
    
    print(f"üì§ Donn√©es nettoy√©es envoy√©es √† DS: {cleaned_data}")
    
    try:
        response = requests.post(api_url, headers=headers, json=cleaned_data)
        
        print(f"üì° R√©ponse DS - Status: {response.status_code}")
        print(f"üì° R√©ponse DS - Contenu: {response.text[:500]}")
        
        if response.status_code == 201:
            return response.json().get("dossier_url", "URL non disponible")
        else:
            return f"Erreur API: {response.status_code} - {response.text}"
    
    except Exception as e:
        print(f"‚ùå Exception lors de l'appel API: {e}")
        return f"Erreur: {str(e)}"

@app.route('/')
def index():
    """Page principale"""
    # Informations sur le statut du mapping
    mapping_status = {
        'loaded': bool(FIELD_MAPPING),
        'filename': os.path.basename(CONFIG_FILE_LOADED) if CONFIG_FILE_LOADED else None,
        'mappings_count': len(FIELD_MAPPING) if FIELD_MAPPING else 0
    }
    return render_template('index.html', mapping_status=mapping_status)

@app.route('/search', methods=['POST'])
def search():
    """Recherche par email et g√©n√©ration des URLs"""
    email = request.form.get('email', '').strip()
    
    if not email:
        return jsonify({'error': 'Email requis'}), 400
    
    # Initialiser le client Grist
    client = GristClient()
    
    # R√©cup√©rer les donn√©es de la table
    df = client.get_table_data(GRIST_TABLE_ID)
    
    if df.empty:
        return jsonify({'error': 'Aucune donn√©e trouv√©e dans la table'}), 404
    
    print(f"üìã Colonnes disponibles dans Grist: {list(df.columns)}")
    print(f"üìã Nombre d'enregistrements: {len(df)}")
    
    # Charger le mapping des champs
    if not FIELD_MAPPING:
        return jsonify({'error': 'Mapping des champs non disponible. V√©rifiez la configuration.'}), 500
    
    # Trouver les colonnes √† afficher
    columns_config = find_display_columns(df)
    
    # Extraire la colonne email pour la recherche
    email_column = columns_config[0]['column']  # Premier √©l√©ment est toujours email
    
    # Filtrer par email
    email_filtered = df[df[email_column].astype(str).str.lower() == email.lower()]
    
    if email_filtered.empty:
        return jsonify({'error': f'Aucun enregistrement trouv√© pour l\'email: {email}'}), 404
    
    # Filtrer par le bool√©en Aide_DGER_demandee = True
    aide_dger_column = None
    for col in df.columns:
        if col.lower() in ['aide_dger_demandee', 'aide_dger_demand√©e'] or col == 'Aide_DGER_demandee':
            aide_dger_column = col
            print(f"‚úÖ Colonne Aide_DGER_demandee trouv√©e: {col}")
            break
    
    if aide_dger_column and aide_dger_column in email_filtered.columns:
        # Filtrer pour ne garder que les enregistrements o√π Aide_DGER_demandee = True
        before_count = len(email_filtered)
        filtered_rows = email_filtered[email_filtered[aide_dger_column] == True]
        after_count = len(filtered_rows)
        
        print(f"üìä Filtrage Aide_DGER_demandee: {before_count} ‚Üí {after_count} enregistrements")
        
        if filtered_rows.empty:
            return jsonify({'error': f'Aucun enregistrement trouv√© pour l\'email {email} pour un dossier Aide DGER'}), 404
    else:
        print(f"‚ö†Ô∏è Colonne Aide_DGER_demandee non trouv√©e, pas de filtrage appliqu√©")
        filtered_rows = email_filtered
    
    # Supprimer les doublons
    filtered_rows = filtered_rows.drop_duplicates()
    
    # Pr√©parer les r√©sultats
    results = []
    
    for _, row in filtered_rows.iterrows():
        # Extraire les donn√©es selon la configuration des colonnes
        row_data = {}
        for config in columns_config:
            column_name = config['column']
            display_name = config['display']
            value = row.get(column_name, '') if column_name in row else ''
            row_data[display_name] = str(value) if value is not None else ''
        
        # G√©n√©rer l'URL pr√©-remplie
        url = generate_prefilled_url(row.to_dict(), FIELD_MAPPING)
        
        result = {
            'data': row_data,
            'url': url
        }
        results.append(result)
    
    # Extraire les noms d'affichage des colonnes
    display_column_names = [config['display'] for config in columns_config]
    
    return jsonify({
        'results': results,
        'columns': display_column_names,
        'total': len(results)
    })

@app.template_filter('dict_items')
def dict_items_filter(d):
    """Filtre pour it√©rer sur les items d'un dictionnaire dans Jinja2"""
    return d.items() if isinstance(d, dict) else []

if __name__ == '__main__':
    print("üöÄ D√©marrage de l'application Flask...")
    print("üìç Interface disponible sur: http://127.0.0.1:5000")
    print("üîó Ou sur: http://localhost:5000")
    print("‚èπÔ∏è  Appuyez sur Ctrl+C pour arr√™ter\n")
    
    app.run(debug=True, host='127.0.0.1', port=5000)